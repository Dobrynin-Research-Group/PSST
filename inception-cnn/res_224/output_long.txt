nohup: ignoring input
device = device(type='cuda')
Epoch	train_loss	train_err[0]	train_err[1]	train_err[2]	test_loss	test_err[0]	test_err[1]	test_err[2]	time
/home/sayko/.local/lib/python3.8/site-packages/scipy/optimize/minpack.py:833: OptimizeWarning: Covariance of the parameters could not be estimated
  warnings.warn('Covariance of the parameters could not be estimated',
1	0.025468	1.8131	12.1566	22.7965	0.009525	2.3261	2.5508	1.0038	342.56
2	0.009717	1.1122	9.8934	36.5101	0.009840	1.5479	3.6719	34.9646	342.85
3	0.008776	1.5616	1.5331	32.0571	0.006896	0.7201	1.5166	2.6958	345.72
4	0.007518	5.5371	4.1746	31.6763	0.006850	0.5435	1.9902	81.1337	355.32
5	0.007077	2.2405	2.8831	29.0003	0.006791	1.1914	3.4460	27.2556	348.88
6	0.006779	1.0282	0.1946	34.9197	0.006520	12.7115	-5.2974	1.1295	354.35
7	0.006491	1.0156	1.5679	30.8209	0.006490	0.9822	1.1757	1.0446	354.93
8	0.006308	0.8237	1.0244	29.9997	0.005948	0.7179	2.3745	20.7630	365.72
9	0.006282	0.7906	1.4684	41.5395	0.006059	1.0414	1.7333	0.9216	354.17
10	0.006201	0.8001	7.0234	28.7008	0.006470	1.1038	0.8631	1.5852	355.36
11	0.006242	0.7663	1.7173	26.8675	0.006144	0.5131	-16.8417	10.2045	355.01
12	0.006018	0.9257	3.3964	28.2709	0.006029	0.7377	-30.8736	1.0414	364.79
13	0.005922	1.5578	1.3804	30.7196	0.005925	0.6714	2.7972	75.2009	366.25
14	0.005890	1.0689	-8.7348	25.4657	0.005976	2.0178	0.6773	0.9352	356.09
15	0.005877	0.8815	-0.9867	29.9101	0.006155	0.5310	2.2448	54.3591	360.24
16	0.005762	0.8332	13.2962	30.0425	0.005342	0.7716	1.7885	15.4144	357.28
17	0.005888	0.8012	0.2737	26.1400	0.005899	2.9327	3.6310	2.7089	355.47
18	0.005780	0.8963	0.8861	30.2380	0.005661	0.6584	1.1853	1.7095	356.71
19	0.005639	0.9358	1.6323	30.2102	0.005381	1.2051	1.8469	41.0912	356.67
20	0.005697	0.8942	1.7336	28.6921	0.006422	0.7937	44.6998	1.1532	354.43
21	0.005527	1.1603	5.3775	27.1317	0.005479	0.6015	0.4666	1.5259	353.49
22	0.005739	0.8810	11.2346	26.8953	0.005588	0.8589	12.3335	17.3715	354.21
23	0.005676	0.7409	2.3867	26.9648	0.005823	1.0793	1.4145	0.9778	354.93
24	0.005458	1.2792	2.5316	37.0005	0.005558	1.3440	5.0655	27.7234	355.05
25	0.005459	1.1172	1.4517	29.0006	0.005664	1.0660	2.9955	0.9252	352.79
26	0.005517	0.8242	2.9082	31.1661	0.005689	0.6417	1.6046	2.4114	353.36
27	0.005538	0.7262	39.4991	24.9616	0.005398	0.8604	2.6617	60.3844	357.11
28	0.005420	0.6770	1.5563	26.2901	0.005574	2.0613	1.3949	3.2475	354.80
29	0.005457	0.8045	2.7882	28.8587	0.005403	0.4937	1.4578	65.0310	356.98
30	0.005435	1.0209	3.7806	26.6785	0.005299	0.8038	0.7825	87.9705	357.59
31	0.005425	0.7249	1.6757	24.1721	0.005447	1.3728	-0.1586	56.4117	353.89
32	0.005350	1.0951	3.3038	32.7352	0.005469	0.7122	1.5096	11.2362	354.86
33	0.005379	0.7213	5.3939	28.3998	0.005027	1.0769	0.7245	67.0761	357.27
34	0.005314	0.6751	2.6580	28.0090	0.005340	0.8544	1.9222	20.1150	355.04
35	0.005302	0.6124	0.8544	25.7745	0.005222	0.6076	inf	66.3426	358.30
36	0.005263	0.6044	0.6535	35.2719	0.005185	0.7351	10.6614	38.6885	355.01
37	0.005280	1.4147	1.7837	27.2953	0.005177	0.7403	0.9735	82.7711	354.29
38	0.005304	0.9937	-1.8764	31.4032	0.005518	0.5997	9.0003	20.1164	352.42
39	0.005325	0.8552	1.8341	33.6236	0.005021	0.6575	1.1829	13.0855	351.35
40	0.005242	0.8406	2.1399	28.5081	0.005044	0.9787	2.1993	6.1050	351.65
41	0.005308	1.0106	0.8401	28.0618	0.005035	1.2519	2.1391	28.5369	353.49
42	0.005312	0.7616	-3.5041	32.6516	0.005654	21.3298	0.1239	38.4788	355.09
43	0.005216	0.6918	2.7112	21.1428	0.005383	0.9136	2.7817	37.9975	352.65
44	0.005177	2.7398	1.3964	22.6347	0.004982	0.9286	1.4161	4.1179	351.04
45	0.005176	1.6736	3.4068	27.0793	0.005278	0.6939	2.2034	11.2950	351.52
46	0.005258	1.7037	-2.7720	27.5127	0.005131	0.7664	3.2915	60.6222	354.29
47	0.005127	0.8792	3.5208	30.7029	0.005118	1.3182	7.9253	4.3760	352.04
48	0.005194	1.1672	3.7175	27.0155	0.004918	1.1667	4.6384	4.6178	353.18
49	0.005258	0.8322	-12.6199	25.4161	0.005172	0.9717	1.6141	39.0642	352.17
50	0.005278	2.3583	1.3046	27.2875	0.005423	1.1510	16.9482	1.0536	351.99
51	0.005240	0.7611	3.7137	31.9368	0.005501	0.9632	1.2560	2.6295	354.13
52	0.005156	0.8806	3.0685	23.9698	0.004765	0.7103	1.1110	5.6811	353.18
53	0.005134	1.1115	-1.7074	26.7094	0.004967	0.8661	1.5703	2.0530	351.33
54	0.005150	0.7095	0.6785	25.8346	0.005222	0.5612	1.1544	48.4798	354.31
55	0.005209	2.8869	7.9591	31.5741	0.004945	0.6148	0.9144	25.2394	355.15
56	0.005061	0.8243	1.9282	26.2535	0.005244	1.2830	2.2175	1.9714	352.81
57	0.005366	0.7261	4.9292	26.0162	0.005013	0.7190	8.8898	1.0615	353.73
58	0.005252	1.2532	1.7196	27.7935	0.005098	1.5574	1.0707	3.7111	353.40
59	0.005128	1.0280	2.8937	34.3551	0.005078	0.8142	1.8766	25.8942	353.95
60	0.005122	0.6443	1.1027	27.9066	0.004965	0.7779	1.7672	7.0787	354.95
61	0.005048	0.9075	2.2286	24.4630	0.005006	0.6397	1.1350	34.8245	352.57
62	0.005200	1.8646	1.5762	23.7415	0.007679	1.4530	4.6248	3.9237	351.69
63	0.005207	1.1696	1.0854	34.4957	0.005047	0.7406	-6.2641	6.8188	350.53
64	0.005297	2.1922	1.7238	26.8431	0.005358	0.6255	1.1650	38.9782	352.67
65	0.005197	0.7598	1.6862	23.4817	0.005077	1.8929	-3.9407	9.3906	353.24
66	0.005058	1.0679	0.1888	28.3416	0.005827	0.7464	2.4128	13.4726	351.69
67	0.005207	0.6489	2.5846	28.9413	0.005233	1.0223	0.1272	14.3207	351.68
68	0.005190	0.8964	4.2945	26.9391	0.004938	1.0110	13.8448	6.9839	352.02
69	0.005152	0.6847	4.0055	24.2712	0.005366	1.3152	-1.3443	46.8856	354.26
70	0.005160	0.8693	0.7722	27.2821	0.005117	0.5737	2.3408	11.2445	352.40
71	0.005109	0.7330	1.3331	28.1456	0.004968	1.2166	0.5138	40.1246	356.13
72	0.005172	0.8561	2.8569	27.4119	0.005022	0.9677	1.8798	54.5699	355.74
73	0.005068	0.7530	1.8981	24.2435	0.005103	0.8214	5.8593	9.3916	354.81
74	0.005106	1.3736	-4.2271	23.6952	0.005392	0.8526	3.9110	4.5118	354.60
75	0.005247	4.0641	1.1822	24.0553	0.004879	0.8562	0.4398	43.6863	352.68
epoch_best_accuracy = 12
epoch_best_loss = 52
