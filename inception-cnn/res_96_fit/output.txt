device = device(type='cuda')
Epoch	train_loss	train_err[0]	train_err[1]	train_err[2]	test_loss	test_err[0]	test_err[1]	test_err[2]	time
/home/sayko/.local/lib/python3.8/site-packages/scipy/optimize/minpack.py:833: OptimizeWarning: Covariance of the parameters could not be estimated
  warnings.warn('Covariance of the parameters could not be estimated',
1	0.025862	3.6471	2.3611	5.9208	0.008670	0.5595	1.0757	0.7416	201.69
2	0.008510	0.6819	0.8958	2.4021	0.008008	1.1039	0.7087	0.6597	201.36
3	0.007876	0.6865	1.0464	1.6545	0.006243	0.4656	0.4061	0.5632	202.79
4	0.006951	0.6562	0.6664	1.1101	0.007118	0.4679	1.2846	0.6123	204.47
5	0.006579	0.4957	0.6075	1.1702	0.006417	0.5365	1.3414	0.5348	206.89
6	0.006254	0.4270	0.5322	2.4169	0.006063	0.3227	0.4522	0.5974	204.07
7	0.006150	0.8153	0.6501	0.6353	0.005795	0.3647	0.3941	0.5196	206.24
8	0.006075	0.4261	0.5257	0.6203	0.006044	0.3039	0.5320	0.7677	205.08
9	0.005950	0.4509	0.4426	0.6202	0.005724	0.4623	0.3335	0.5477	207.80
10	0.005819	0.3982	0.4738	0.5919	0.005519	0.5052	0.2795	0.6244	207.27
11	0.005753	0.4893	0.3912	0.5876	0.005914	0.3287	0.3802	0.8140	208.07
12	0.005780	0.6360	0.6120	0.5928	0.005984	0.4644	0.3378	0.5052	208.25
13	0.005663	0.4872	0.4510	0.5754	0.005639	0.3413	0.4867	0.5999	206.57
14	0.005669	0.3834	0.4730	0.5711	0.005544	0.3624	0.3787	0.5993	205.80
15	0.005614	0.5176	0.7744	0.5688	0.005572	0.4288	0.4596	0.4894	206.30
16	0.005593	0.3674	0.4412	0.5655	0.005879	0.4249	0.2458	0.7855	207.33
17	0.005563	0.3703	0.4149	0.5587	0.005642	0.3439	0.3929	0.6569	208.48
18	0.005548	0.3775	0.5285	0.5544	0.005386	0.5152	0.4518	0.4919	207.02
19	0.005452	0.7617	0.4295	0.5488	0.005447	0.3469	0.3195	0.6584	207.56
20	0.005388	0.5193	0.5025	0.5435	0.005239	0.2631	0.3062	0.5144	207.07
21	0.005413	0.4461	0.9002	0.5391	0.005441	0.4138	0.3443	0.6022	205.75
22	0.005471	0.3889	0.3933	0.5472	0.005270	0.2842	0.3901	0.5343	206.94
23	0.005352	0.3651	0.4230	0.5342	0.005400	0.2708	3.3428	0.5240	206.56
24	0.005389	0.3371	0.6453	0.5412	0.006135	0.3635	0.7693	0.6111	207.82
25	0.005264	0.3856	0.7145	0.5273	0.005632	0.3474	0.4208	0.6216	207.64
26	0.005384	0.4724	0.4216	0.5388	0.005519	0.3226	0.3900	0.6567	208.31
27	0.005242	0.4266	0.3896	0.5363	0.005334	0.6135	0.2520	0.5214	207.48
28	0.005369	0.3396	0.7063	0.5290	0.005603	0.3079	1.0082	0.4609	207.48
29	0.005289	0.3192	0.4503	0.5268	0.005160	0.2760	0.2813	0.5747	206.98
30	0.005328	0.4172	0.3790	0.5230	0.005190	0.6185	0.3438	0.4754	206.99
31	0.005267	0.5362	0.8725	0.5252	0.005378	0.2832	0.8518	0.4685	206.92
32	0.005309	0.3584	0.5826	0.5322	0.005040	0.2640	0.4865	0.5138	207.14
33	0.005278	0.4347	0.3335	0.5218	0.005238	inf	0.5884	0.4698	205.89
34	0.005256	0.3742	0.4316	0.5197	0.005263	0.2927	0.3180	0.5946	207.15
35	0.005209	0.3103	0.4239	0.5160	0.005466	0.5896	0.2923	0.5104	206.77
36	0.005270	0.4668	0.3538	0.5188	0.005321	0.3960	0.2946	0.6251	207.95
37	0.005261	0.5080	0.4741	0.5215	0.005162	0.3156	0.4482	0.4365	208.04
38	0.005184	0.4760	0.3505	0.5222	0.005272	0.5149	1.1519	0.4905	206.46
39	0.005194	0.4260	0.3875	0.5189	0.005106	0.2475	0.3136	0.4881	206.51
40	0.005238	0.3703	0.7662	0.5172	0.005093	0.2848	0.2675	0.4787	206.59
41	0.005215	0.5217	0.3881	0.5114	0.005014	0.5887	0.4115	0.4429	208.29
42	0.005229	0.4892	0.4024	0.5137	0.005089	0.3912	0.7253	0.4585	209.33
43	0.005198	0.3181	0.3473	0.5163	0.005042	0.3547	0.4303	0.4487	208.67
44	0.005195	0.8609	0.4702	0.5155	0.005256	0.2355	0.2849	0.5501	207.33
45	0.005247	0.3215	0.4697	0.5169	0.005128	0.3120	0.3028	0.4524	209.32
46	0.005125	0.3601	0.4689	0.5067	0.005046	0.2834	0.3326	0.5278	209.69
47	0.005165	0.4488	0.5201	0.5107	0.005134	0.4373	0.3410	0.5797	207.94
48	0.005140	0.3307	0.4314	0.5052	0.005059	0.3873	0.3640	0.5362	208.17
49	0.005085	1.1310	0.3699	0.5106	0.005237	0.3304	0.3159	0.5897	208.97
50	0.005121	0.9627	0.8676	0.5075	0.005110	0.3009	0.3730	0.4904	208.44
51	0.005177	0.6198	0.4042	0.5082	0.005063	0.2675	0.2347	0.5453	209.19
52	0.005149	0.3847	0.5166	0.5093	0.005193	0.2973	0.4063	0.4848	207.72
53	0.005145	0.3765	0.4073	0.5019	0.004848	0.2525	1.4262	0.4920	208.50
54	0.005055	0.5565	1.1378	0.5055	0.005072	0.3295	0.3736	0.4884	207.38
55	0.005156	0.7735	0.7444	0.5068	0.005278	0.3481	0.4521	0.5997	209.21
56	0.005165	0.3260	0.4348	0.4983	0.004991	0.2538	0.2425	0.4952	208.85
57	0.005130	0.4211	0.3700	0.4983	0.005162	0.5390	0.3229	0.4495	209.11
58	0.005060	0.4798	0.4129	0.5089	0.005404	0.3996	0.5658	0.4515	208.77
59	0.005157	0.4501	0.7433	0.5022	0.004923	0.4167	0.4428	0.5196	209.02
60	0.005060	0.3657	0.3531	0.5031	0.005000	0.2510	1.0651	0.4588	208.94
61	0.005111	0.7409	0.7659	0.4995	0.005255	0.3777	2.4210	0.6517	208.96
62	0.005119	0.6905	0.3436	0.5017	0.005058	0.4200	0.7117	0.4195	208.33
63	0.005070	0.2925	0.4239	0.4994	0.005120	0.2649	0.3063	0.5487	208.81
64	0.005123	0.3906	0.4109	0.5041	0.005046	0.2907	0.3965	0.5136	208.83
65	0.005153	1.9841	0.3744	0.5049	0.005070	0.7177	0.6501	0.4341	209.06
66	0.005103	0.3863	2.1304	0.5002	0.005116	0.3414	0.9680	0.4847	208.72
67	0.005157	0.4480	0.4028	0.4996	0.005012	0.4820	0.5074	0.4494	208.73
68	0.005122	0.3354	0.3502	0.5005	0.005026	0.4590	0.4519	0.4406	208.69
69	0.005042	0.5178	0.5300	0.4958	0.005157	0.3204	0.3416	0.5239	208.85
70	0.005122	0.3384	0.4250	0.5008	0.005231	0.7148	0.3820	0.4906	208.80
71	0.005112	0.5174	0.3689	0.4960	0.005036	0.6606	0.5757	0.4349	209.02
72	0.005076	1.0483	0.5643	0.4982	0.004773	0.3256	0.3049	0.4558	207.46
73	0.005077	0.3021	0.3407	0.4949	0.004893	0.3112	0.4996	0.4783	208.81
74	0.005055	0.4028	0.3460	0.4959	0.005209	0.2655	0.3532	0.4800	208.47
75	0.005003	0.3342	0.3373	0.4984	0.005093	0.3546	0.4119	0.4349	208.34
76	0.005040	0.4700	0.2923	0.4894	0.004906	0.2700	0.2316	0.4953	208.38
77	0.005086	0.5490	0.6287	0.4863	0.004991	0.3872	0.4323	0.4342	209.03
78	0.005021	0.2896	0.3834	0.4939	0.004955	0.2509	0.3297	0.4683	207.50
79	0.005026	0.7515	0.4059	0.4925	0.004958	0.3811	0.3141	0.4758	207.18
80	0.005032	0.3914	0.7047	0.4884	0.004830	0.3579	0.3215	0.4833	207.40
81	0.004976	0.3667	0.3339	0.4890	0.005242	0.3562	2.0531	0.6554	207.17
82	0.005065	0.3525	0.4709	0.4903	0.005243	0.5223	0.3304	0.5302	208.12
83	0.005044	0.4237	0.3456	0.4944	0.005123	0.3792	0.7070	0.4461	209.07
84	0.005075	0.3653	0.5313	0.4917	0.005286	0.2735	0.3894	0.4985	208.62
85	0.005045	0.3744	0.4701	0.4960	0.004913	0.2881	0.2443	0.5475	208.80
86	0.005032	0.3144	0.4316	0.4945	0.004958	0.4557	0.5088	0.4340	208.59
87	0.005144	0.3277	0.3823	0.6663	0.007804	1.2641	0.8875	2.3456	208.82
88	0.005052	0.5326	0.3332	0.4929	0.005015	0.2882	0.3722	0.4845	208.40
89	0.005002	0.3373	0.3284	0.4893	0.005072	0.2631	0.3064	0.5210	208.68
90	0.004997	0.3547	0.6157	0.4905	0.004788	0.3980	0.3450	0.4350	208.77
91	0.005001	0.9203	0.3384	0.4915	0.004923	0.3015	0.3130	0.5652	208.90
92	0.005001	0.9878	1.5284	0.4858	0.004882	0.4376	0.3136	0.4171	208.46
93	0.005015	0.9039	0.4291	0.4865	0.004749	0.2772	0.2692	0.4553	208.71
94	0.004965	0.3899	0.3700	0.4998	0.004935	0.2593	0.3984	0.5019	208.32
95	0.004979	0.3907	0.7289	0.4846	0.004953	0.3182	0.4026	0.4541	208.03
96	0.004991	0.3357	0.4261	0.4854	0.004890	0.2531	0.2290	0.4976	206.98
97	0.004930	0.3360	0.5670	0.4868	0.005102	0.2965	0.3716	0.4861	208.80
98	0.004934	0.5338	0.7288	0.4844	0.005069	0.3156	0.3054	0.4550	208.75
99	0.004973	0.3281	0.3938	0.4779	0.004935	0.2489	1.1077	0.4789	209.06
100	0.005114	0.3338	0.3908	0.4884	0.004914	0.4008	0.5513	0.4339	208.27
epoch_best_accuracy = 16
